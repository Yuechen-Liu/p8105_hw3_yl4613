---
title: "p8105_hw3_yl4613 codes"
author: "YuechenLiu"
date: "10/9/2020"
output: html_document
---


```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)
library(patchwork)
knitr::opts_chunk$set(
	fig.width = 6,
	fig.asp = .6,
	out.width = '90%'
)

theme_set(theme_minimal() + theme(legend.position = 'bottom'))

options(
	ggplot2.continuous.colour = 'viridis',
	ggplot2.continuous.fill = 'viridis'
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` and `r ncol(instacart)` columns.

Observations are the level of items in order by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes.

How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```


Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>%
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) +
	geom_point() +
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


Apples vs ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c('Pink Lady Apples', 'Coffee Ice Cream')) %>%
	group_by(product_name, order_dow) %>%
	summarize(mean_hour = mean(order_hour_of_day)) %>%
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)

```


### Problem 2
### load and tidy the data
```{r}
ac_data = read.csv(
	'./accel_data.csv') %>% 
	janitor::clean_names() %>% 
	pivot_longer(activity_1:activity_1440,
							 names_to = 'minute_of_the_day',
							 values_to = 'activity_counts',
							 names_prefix = 'activity_') %>% 
	mutate(
		type_of_day = case_when(
			day %in% c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday') ~ 'weekday',
			day %in% c('Saturday', 'Sunday') ~ 'weekend'),
			day = as.factor(day),
		minute_of_the_day = as.integer(minute_of_the_day), 
		type_of_day = as.factor(type_of_day))
```
The resulting data is tidier than the original dataset. It contains: number of the week (1-5), day_id(useless now so I left it alone), name of the data (Monday-Sunday), minute of the day (1-1440, every minute of a single day), activity_counts(the activity counts for each minute of that day), type_of_day(Monday-Friday are defined as weekdays, Saturday and Sunday are defined as weekends). There are `r nrow(ac_data)` observations in total, which contains 5 weeks, 35 days. So every day there are `r nrow(ac_data)/35` observations.

Traditional analyses--total activity of the day.
```{r}
sum_data = 
	tibble(ac_data) %>% 
	group_by(day, week) %>% 
	summarize(activity_of_day = sum(activity_counts)) %>% 
	relocate(week) %>% 
	arrange(week) %>% 
	pivot_wider(
		names_from = day,
		values_from = activity_of_day) %>% 
	relocate(week, Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday)
sum_data
```
Trends: The activity data during the middle of the week is more stable than that in weekends. For every week, week 1-3 have the most activities, whereas activities reduced during the last two weeks. 

Plotting-24 hour activity
```{r}
ac_data %>% 
	ggplot(aes(x = minute_of_the_day, y = activity_counts , color = day)) +
	geom_line(alpha = .4) + 
	labs(x = 'minute of the day',
			 y = 'numbers of activity',
			 title = 'Activities every minute during a day')
```
From this plot, we can see that the activities during daytime are higher, and during the night are lower. It indicates that this patient has a daily routine that: wakes up ~7-8 am, have some activities before noon. He might take a nap / have some rest in the afternoon. He has high activity during ~8-11pm. And he sleeps usually after 11pm.


###Problem 3
###load the data
```{r}
library(p8105.datasets)
data("ny_noaa")
```
Description: This dataset is about some weather-related parameters in NY these decades. These parameters include precipitation, snow fall, snow depth, maximum and minimum temperature. We have `r nrow(ny_noaa)`observations and `r ncol(ny_noaa)` variables. As for the missing data, that of temperatures are very obvious in the 80's and 90's. After converting, temperature are in degree celsius, and data about snow/precipitation are in mm.

Data cleaning
```{r}
ny = 
	ny_noaa %>% 
	janitor::clean_names() %>% 
	separate(date, c('year','month','day')) %>% 
	mutate(
		prcp_mm = prcp / 10,
		snow_mm = as.numeric(snow),
		snwd_mm = as.numeric(snwd),
		tmax = as.numeric(tmax),
		tmax_C = tmax / 10,
		tmin = as.numeric(tmin),
		tmin_C = tmin / 10
		) %>% 
	select(-'prcp', -'snow', -'snwd', -'tmax', -'tmin')
ny %>% 
	count(snow_mm) %>% 
	arrange(desc(n))
```
For snow fall, 0 is the most observed value. Because NY has no snow in most days of a year (even though it's very cold).

Two-panel plot showing the average max temperature in January and in July in each station across years.
```{r}
Jan_Jul = 
	ny %>% 
	filter(month %in% c('01', '07')) %>%
	filter(!is.na(tmax_C)) %>%
	group_by(id, year, month) %>%
	summarize(
		avg_tmax = mean(tmax_C)
	)
Jan_Jul %>% 
	ggplot(aes(x = year, y = avg_tmax, color = month, group = id))+
	geom_point()+
	labs(y = 'average maximum temperature',
			 title = 'average max temperature in January and in July in each station across years')+
	facet_grid(. ~ month)+
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
	

```
From the box plot, we can see that: In January from all years, the average maximum temperature is becoming more unstable--larger differences between years, and generally higher temperature in recent years. Compared to maximum temperatures in January, those in July are more stable and have smaller ranges (because summer is always pretty hot, but winter could be extremely cold/commonly cold/even a bit warm). There are outliers in most of the months, among them, in 1982 and 2005, ny had very cold days in Jan; in 1988, ny had a lowest maximum temperature in July.

Make a two-panel plot showing (i) tmax vs tmin for the full dataset.

```{r}
max_min = 
	ny %>% 
	ggplot(aes(x = tmin_C, y = tmax_C))+
	geom_smooth()+
	labs(
		y = 'maximum temperature',
		x = 'minimum temperature',
		title = 'Max temp vs. Min temp'
	)

```
Comment: we can see that there is a huge difference in max vs min temperature in NY. There are extremely cold/ hot places, there are also mild-temperature places. 

Make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.
```{r}
snow_distribution = 
	ny %>% 
	filter(snow_mm > 0, snow_mm < 100) %>% 
	ggplot(aes(x = year, y = snow_mm))+
	geom_boxplot()+
	labs(y = 'Year',
			 y = 'Snowfall(mm)',
			 title = 'distribution of snowfall')+
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
(max_min) + (snow_distribution)
```

Comment: Distribution of snowfall were stable in the old days, but started to become a bit unstable from 1998. Then there were outliers in 2006 and 2010, more extreme snow distribution appeared in recent years.

 














